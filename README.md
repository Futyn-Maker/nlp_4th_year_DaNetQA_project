# DaNetQA Project

**Андрей Якубой, Алиса Лёзина, Полина Уткина**

В этой работе мы проводим небольшое исследование методов решения задачи ответов на вопросы "да"/"нет" для русского языка. Данные вопросы основаны на информации из небольших фрагментов текста, которые идут вместе с вопросами, при этом далеко не всегда ответ на вопрос содержится в тексте напрямую, так что для правильного ответа необходимо понять смысл текста и обладать базовыми способностями рассуждать логически. Представляется, что такой тест позволяет понять, как хорошо конкретная языковая модель способна понимать смысл прочитанного русскоязычного текста, а также, в случае с классификацией и энкодерами - насколько хорошо выбранное векторное представление текста передаёт его смысл.

В этой работе мы используем датасет DaNetQA, который является частью бенчмарка [Russian SuperGlue](https://russiansuperglue.com/).

## EDA

Датасет DaNetQA является бенчмарком для задачи бинарного QA.

Состав датасета: вопрос ("question"), текст ("passage"), бинарный ответ ("label" в формате "True/False"), индекс строки ("idx").

Размер датасета: 1789 строк в трейне, 805 строк в тесте и 821 строка в валидации.

В трейне наблюдается некоторый дисбаланс лейблов: 1061 True, 688 False;

Это, возможно, может приводить к некоторому байасу в сторону положительных ответов во время обучения моделей.

Тексты трейна распределены по длине относительно нормально, средняя длина: 98 слов. В случае валидации распределение несколько менее равномерное, средняя длина: 91 слово.

## Метрики и выборки

Поскольку оригинальная тестовая выборка бенчмарка не содержит меток, мы не можем использовать её для оценивания. При этом мы имеем достаточно большую валидационную выборку относительно тренировочной (не многим меньше 50%). Для целей нашего проекта мы разделили валидационную выборку на две равные части с сохранением пропорций классов, и одну из них использовали в качестве валидационной выборки, а другую - в качестве тестовой.

В тренировочной выборке присутствует дисбаланс классов, однако в валидационной и тестовой выборках его нет - поэтому для нас будут показательны как accuracy, так и F1-метрика и её компоненты - precision и recall. Мы анализировали все метрики, но судили о качестве модели именно по accuracy, так как эта метрика используется на лидерборде в Russian SuperGlue, что даёт нам возможность сравнивать результат. Precision, recall и F1 мы использовали для анализа байасов.

## Baseline

В качестве бейзлайна разработчики Russian SuperGLUE использовали TF-IDF и логистическую регрессию ([источник](https://github.com/RussianNLP/RussianSuperGLUE/blob/master/tfidf_baseline/DaNetQA.py)). Нам показалось это хорошим решением в качестве стартовой точки, однако в оригинальном бейзлайне есть моменты, которые нас смутили.

1. Авторы подавали на вход только вопросы и ответы, никак не учитывая текстовые фрагменты, в которых можно было бы найти ответ на вопрос.
2. Авторы никак не предобрабатывали текст, подаваемый в TF-IDF, не проводилась даже лемматизация и удаление стоп-слов.

Кроме того, в авторском бейзлайне используется векторизатор TF-IDF, обученный на всём тренировочном корпусе бенчмарка, а не только на датасете DaNetQA. Мы же в данном проекте ориентируемся не на весь бенчмарк, а исключительно на этот набор данных. Поэтому, вдохновляясь оригиналом, мы немного модифицировали бейзлайн: добавили лемматизацию и удаление стоп-слов, построили TF-IDF с учётом биграмм, а также провели два эксперимента: в первом в качестве объектов использовались только вопросы, а во втором текст, содержащий ответ, конкатинировался с вопросом.

Результаты получились следующие. Во-первых, в обоих экспериментах мы наблюдали жёсткое переобучение: метрики на тренировочном наборе данных намного выше, чем на тестовом и валидационном. Однако даже по метрикам на тренировочном наборе заметно, что модель чаще склонна говорить "да", даже если ответ на вопрос отрицательный - это видно по метрике recall. На тестовом и валидационном наборах данных "yes-bias" модели совсем критичный: для ответов "да" recall почти стопроцентный, тогда как для "нет" едва ли больше 10%, то есть модель почти всегда говорит "да". Видимо, это происходит из-за дисбаланса данных в тренировочной выборке, где вопросов с правильным утвердительным ответом больше.

Во-вторых, вопреки ожиданиям, добавление дополнительной информации в виде фрагмента текста ухудшило результат. Это можно связать с тем, что логистическая регрессия не способна моделировать логические отношения между текстом и вопросом, да и представление TF-IDF для этого не подходит, потому что не содержит никакой информации о семантике - в итоге когда мы добавляем больше текста, появляется больше шума, а новой информации для обобщения не появляется.

В целом, baseline-модель вообще не выучила никаких закономерностей и получилась почти константной, что говорит о том, что TF-IDF не подходит для моделирования логической связи между вопросом и текстом, в котором этот вопрос содержится, да и логистическая регрессия, видимо, тоже. Для решения задачи стоит задействовать глубокое обучение, как для получения адекватного представления текста, так и для классификации, или, что ещё лучше, перейти от задачи классификации к задаче генерации.

## Классификация с помощью предобученного инструктивного энкодера и MLP

Современные энкодеры способны эффективно вычислять эмбеддинги сразу для предложений. Они специально обучались на множестве датасетов под разные задачи: классификация, кластеризация, QA, информационный поиск и так далее. Есть несколько SOTA-энкодеров, которые обучались с использованием инструкций - это значит, что они могут строить разные эмбеддинги в зависимости от данных инструкций: одни будут больше подходить для классификации, другие - для кластеризации, и так далее. Мы взяли одну из таких моделей, а именно, [multilingual-e5-large-instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct), составили инструкцию для бинарного QA, получили эмбеддинги и обучили простой MLP-классификатор с их использованием.

Это, во-первых, требует меньше памяти, чем fine-tuning трансформера, во-вторых, как казалось, могло дать даже лучший результат за счёт того, что модель обучена на разных supervised-датасетах и может производить высококачественные представления текста.

При обучении мы подбирали гиперпараметры: learning rate, dropout и weight_decay - в надежде побороть переобучение. Гиперпараметры подбирали последовательно в вышеперечисленном порядке.

Наша инструкция для энкодера выглядела следующим образом:

> Given a question and the passage, answer 'yes' or 'no' to this question based on the passage

В самом запросе мы объединили текстовый фрагмент и вопрос в формате `Passage: {passage}\nQuestion: {question}`.

Результат получился намного лучше, чем в случае с TF-IDF (accuracy=0.69), теперь модель нельзя назвать константной. Однако даже после подбора параметров наблюдается сильный перекос в сторону положительных ответов, что заметно по метрике recall для False, причём увеличение weight_decay с 1e-5 до 1e-2 вопреки интуиции только усиливало переобучение, и только 1e-1 немного, в рамках статистической погрешности, улучшил изначальный результат.

## Fine-tuning

Вообще, к задаче бинарного QA представляется логичным подходить как к задаче NLI, где модель получает некоторый текст, стимул, и пытается установить связь между текстом и стимулом - здесь в качестве такой связи выступают ответы "да"/"нет". BERT-like-модели активно тестируют на NLI, хотя с точки зрения ML это всё ещё такая же классификация.

Мы попробовали дообучить XML-RoBERTa-Large на задачу классификации по аналогии с NLI. Эта модель была выбрана, потому что она мультиязычная, лучше простого BERT и, главное, лежит в основе Multilingual-E5-Large-Instruct, которую мы использовали ранее.

Здесь мы автоматически не подбирали гиперпараметры, поскольку для того, чтобы результат был хоть немного осмысленной, нужно как минимум 3 эпохи обучения, и с подбором хотя бы LR и weight_decay в сумме обучение заняло бы очень много времени и ресурсов. Однако мы поставили weight_decay повыше, чем базовый 0.01, в попытках избежать переобучения - это выяснилось опытным путём.

К сожалению, результат получился хуже, чем при тренировки MLP-классификатора на готовых эмбеддингах (0.67 против 0.69), при этом по динамике обучения было видно, что модель легко начинает переобучаться и не особо стабильна (лосс на трене стабильно падал, а лосс на валидационной выборке под конец активно рос). При этом чем меньше accuracy, тем больше recall, что говорит о увеличении recall за счёт его увеличения для положительного класса - модель в целом получилась ещё более "yes-biased", чем предыдущая.

Вероятно, этот результат можно немного улучшить за счёт более тщательного подбора гиперпараметров - на официальном лидерборде Russian SuperGlue у такой же модели accuracy на этом датасете равно 0.757 (хотя они использовали другой тестовый набор данных), но, кажется, от истины мы не очень далеко и лучших цифр от классификации не добиться.

## LLM

Наконец, от классификации мы перешли к самому интересному эксперименту - генерации. Мы оценили, как разные небольшие генеративные языковые модели понимают русскоязычный текст. Мы рассмотрели только самые современные модели.

1. [Qwen2.5-0.5B-Instruct](huggingface.co/qwen/Qwen2.5-0.5B-Instruct) - самая маленькая модель семейства Qwen-2.5 от китайских коллег. В этих моделях в принципе заявлено хорошее понимание русского языка, но очень навряд ли для совсем маленьких моделей, типа этой. Однако её можно запустить где угодно!
2. [Qwen2.5-7B-Instruct](huggingface.co/qwen/Qwen2.5-7B-Instruct) - модель того же семейства, но побольше, и по размерам уже подходит для каких-то базовых бизнес-кейсов и, представляется, сильно лучше понимает русский язык.
3. [T-lite-it-1.0](https://huggingface.co/t-tech/T-lite-it-1.0) - совсем свежая модель от Т-технологий 🎄, которая, по словам создателей, представляет собой сильно улучшенный для русского языка Qwen-2.5: делали как претрейн, так и дообучение на русскоязычных инструктивных датасетах. По идеи должна справиться с задачей ещё лучше.
4. [Ministral-8B-Instruct-2410](https://huggingface.co/mistralai/Ministral-8B-Instruct-2410) - ещё одна свежая небольшая модель от MistralAI. Русский язык заявлен официально.

Таким образом, все модели, кроме первой, были в одном размере. Модели больше мы не тестировали, так как у нас нет соответствующих ресурсов, да и интересно посмотреть на перформанс именно маленьких лёгких в использовании моделей.

Отметим, что, естественно, мы работали с моделями в zero-shot-сетапе: никакого дообучения мы не проводили (это также требует много ресурсов и в целом сильно сложнее, чем дообучение на задачу классификации). Примеров (few-shot) тоже не давали, так как это представляется бессмысленным для таких разных вопросов и в принципе для NLI-like-задачи, да и способность понимать текст у таких моделей уже должна быть.

Для Qwen и Ministral мы использовали инструкцию на английском языке, для T-lite - на русском. Алгоритм простой: для каждого примера из тестового набора данных мы просили модель прочитать текст и ответить на вопрос только "да" или "нет", без дополнительных объяснений. Ризонинг мог бы повысить качество, но тогда результат было бы сложно или невозможно оценивать автоматически.

Для всех экспериментов мы установили очень низкую температуру 0.1, чтобы модель строго следовала инструкциям и меньше "креативила", а больше смотрела на текст. Поэкспериментировать с параметрами генерации было бы можно, однако это представляется не самым осмысленным: мы знаем, что увеличение температуры повышает разнообразие в ответах, а нам для нашей задачи этого как раз не нужно.

* Промпт для Qwen и Ministral: `Read the following text and answer the question below it only with one word in Russian: 'да' or 'нет'. Do not provide any explanations.\n\nText: {text}\n\nQuestion: {question}`
* Промпт для T-lite: `Прочитай текст и ответь на вопрос после него одним словом: 'да' или 'нет' без дополнительных пояснений.\n\nТекст: {text}\n\nВопрос: {question}`

В результате получилось, что модели класса 7-8B показали очень неплохой результат, и он намного лучше, чем результаты, полученные нами при экспериментах с классификацией. Видно, что метрики precision и recall достаточно равномерны по классам, причём даже есть совсем небольшой сдвиг в сторону отрицательных ответов.

Самая маленькая модель, ожидаемо, справилась очень плохо, показав yes-bias даже хуже, чем у бейзлайна - зато модель хорошо следовала инструкции и не ответила ничего лишнего, что уже для такой крошки приятно удивительно.

Самое неожиданное, однако, это то, что модель T-lite показала себя немного хуже, чем базовая Qwen-2.5! Нельзя утверждать, что модель однозначно хуже в этой задаче, потому что разница всего в 1%, но ожидаемого прироста в обработке русскоязычных текстов тоже не наблюдается. Возможно, для этой модели лучше подходят какие-то другие параметры генерации, однако результат интересный и заставляет задуматься.

## Анализ ошибок

Для анализа ошибок мы посмотрели на первые 15 строк с несовпадающими ответами и предсказаниями у каждой модели из всех наших экспериментов.

В общих чертах, можно отметить, что многие модели ошибаются буквально в одних и тех же предложениях. Чаще всего они не справляются именно с задачей NLI - когда что-то не упоминается напрямую и не очень очевидно без экстралингвистических знаний, они несколько теряются.

В ошибках, однако, совсем мало паттернов, которые можно отследить вручную. Иногда модельку сбивают с толку синонимы, иногда - напрямую отсутствие необходимой информации в пассаже.

И в этом их нельзя винить! Например, кажется, что и человеку иногда достаточно сложно определить, к кому реферирует "хозяин" в "Сразу после свадьбы Михаил Калашников сообщил о ней Пушкину, не забыв выразить благодарность своему хозяину.", чтобы ответить утвердительно на вопрос "Были ли у пушкина крепостные?" (в ответе на этот вопрос ошиблось точно больше половины моделей, если не все).

## Заключение

Мы исследовали разные методы решения задачи бинарного QA. Получилось, что все наши эксперименты так или иначе побили бейзлайн, представляющий собой представление TF-IDF и простую логистическую регрессию. В экспериментах, связанных с классификацией, активно возникала проблема переобучения и из-за этого "yes-bias": тренировочная выборка была с перекосом классов, а с другой стороны, BERT-like-модели не достаточно большие, чтобы улавливать такие логические связи. Мы показали, что обучение простого классификатора на основе современных предобученных энкодеров может дать не худший, а иногда и лучший результат на задаче ответа на вопросы, а возможно и на других NLI-like-задачах, по сравнению с дообучением самого трансформера - при меньшей затрате ресурсов.

Что касается генерации, большие инструктивные языковые модели ожидаемо справились лучше, так как благодаря своим размерам и огромным размерам обучающих выборок способны анализировать прочитанное. Здесь не было проблемы дисбаланса классов, так как тренировочная выборка никак не использовалась и не влияла на ответы моделей. При этом самые маленькие из LLM ещё не годятся для анализа русскоязычного текста, а дообученные "русскоязычные" LLM не обязательно будут показывать лучший результат, чем их базовые версии.

Из перспектив: конечно, интересно было бы проверить модели и побольше, а также дообучить модели на тренировочной выборке, чтобы посмотреть, как повлияет дисбаланс классов, а также интересно посмотреть на методы информационного поиска и предсказывать не бинарный ответ на вопрос, а фрагмент текста, в котором этот ответ есть.
